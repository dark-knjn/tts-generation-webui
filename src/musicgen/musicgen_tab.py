"""
Copyright (c) Meta Platforms, Inc. and affiliates.
All rights reserved.

This source code is licensed under the MIT license found in 
https://github.com/facebookresearch/audiocraft/blob/main/LICENSE
"""

import torch
import gradio as gr
from audiocraft.models import MusicGen


MODEL = None


def load_model(version):
    print("Loading model", version)
    return MusicGen.get_pretrained(version)


def predict(model, text, melody, duration, topk, topp, temperature, cfg_coef):
    global MODEL
    topk = int(topk)
    if MODEL is None or MODEL.name != model:
        MODEL = load_model(model)

    if duration > MODEL.lm.cfg.dataset.segment_duration:
        raise gr.Error("MusicGen currently supports durations of up to 30 seconds!")
    MODEL.set_generation_params(
        use_sampling=True,
        top_k=topk,
        top_p=topp,
        temperature=temperature,
        cfg_coef=cfg_coef,
        duration=duration,
    )

    if melody:
        sr, melody = melody[0], torch.from_numpy(melody[1]).to(
            MODEL.device
        ).float().t().unsqueeze(0)
        print(melody.shape)
        if melody.dim() == 2:
            melody = melody[None]
        melody = melody[..., : int(sr * MODEL.lm.cfg.dataset.segment_duration)]
        output = MODEL.generate_with_chroma(
            descriptions=[text],
            melody_wavs=melody,
            melody_sample_rate=sr,
            progress=False,
        )
    else:
        output = MODEL.generate(descriptions=[text], progress=False)

    output = output.detach().cpu().numpy()
    return MODEL.sample_rate, output


def generation_tab_musicgen():
    with gr.Tab("Generation (MusicGen) Demo"):
        gr.Markdown(
            """
            # MusicGen

            This is the demo for MusicGen, a simple and controllable model for music generation presented at: "Simple and Controllable Music Generation".

            Below we present 3 model variations:
            1. Melody -- a music generation model capable of generating music condition on text and melody inputs. **Note**, you can also use text only.
            2. Small -- a 300M transformer decoder conditioned on text only.
            3. Medium -- a 1.5B transformer decoder conditioned on text only.
            4. Large -- a 3.3B transformer decoder conditioned on text only (might OOM for the longest sequences.)

            When the optional melody conditioning wav is provided, the model will extract
            a broad melody and try to follow it in the generated samples.

            For skipping queue, you can duplicate this space, and upgrade to GPU in the settings.
            <br/>
            <a href="https://huggingface.co/spaces/musicgen/MusicGen?duplicate=true">
            <img style="margin-top: 0em; margin-bottom: 0em" src="https://bit.ly/3gLdBN6" alt="Duplicate Space"></a>
            </p>

            See [github.com/facebookresearch/audiocraft](https://github.com/facebookresearch/audiocraft)
            for more details.
            """
        )
        with gr.Row():
            with gr.Column():
                with gr.Row():
                    text = gr.Text(label="Input Text", interactive=True)
                    melody = gr.Audio(
                        source="upload",
                        type="numpy",
                        label="Melody Condition (optional)",
                        interactive=True,
                    )
                with gr.Row():
                    submit = gr.Button("Submit")
                with gr.Row():
                    model = gr.Radio(
                        ["melody", "medium", "small", "large"],
                        label="Model",
                        value="melody",
                        interactive=True,
                    )
                with gr.Row():
                    duration = gr.Slider(
                        minimum=1,
                        maximum=30,
                        value=10,
                        label="Duration",
                        interactive=True,
                    )
                with gr.Row():
                    topk = gr.Number(label="Top-k", value=250, interactive=True)
                    topp = gr.Number(label="Top-p", value=0, interactive=True)
                    temperature = gr.Number(
                        label="Temperature", value=1.0, interactive=True
                    )
                    cfg_coef = gr.Number(
                        label="Classifier Free Guidance", value=3.0, interactive=True
                    )
            with gr.Column():
                output = gr.Audio(label="Generated Music", type="numpy")
        submit.click(
            predict,
            inputs=[model, text, melody, duration, topk, topp, temperature, cfg_coef],
            outputs=[output],
        )
